module Parsers.ContinuationParser.Examples.LispyListTutorial.UserData where

import Parsers.ContinuationParser.Examples.ParseUserData as ParseUserData

import Parsers.ContinuationParser.Examples.FieldExtras as FieldExtras

userData = flow down [[markdown|
# Our first parser

Say we have the String:
````
Name: Timothy Hobbs
Location: Prague
Ocupation: Programmer
````
And we want to put it into a record of

````
type UserData =
 {name:String
 ,location:String
 ,occupation:String}
````

### What is our parser going to do?

 - Consume the `Name:` field
 - Consume anything following the `Name:` marker right up till the end of that line
 - Convert that to a string
 - Trim off the whitespace
 - Use that trimmed string as our first intermediate value.
 - Repeat for `Location:` and `Occupation:`
 - Consume whitespace untill we reach the end of input, throwing an error if we find any garbage at the end of the file.

#### Basic imports

We'll start by importing some modules from the continuation-parser library:
|]
 ,[markdown|

````
import open Parsers.ContinuationParser
import open Parsers.ContinuationParser.LexemeEaters
import open Parsers.CharacterClassification -- (isWhitespace)

import String
````
|]
 ,[markdown|
The ContinuationParser module provides the basic functions and data types that we'll need to do our parsing.  The LexemeEaters module provides basic functions for constructing new LexemeEaters. We also import String, because our parser will work with lists of characters rather than Noelm Strings and so we'll need to convert between the two.

#### Preperatory boiler-plate
It is possible to configure the `take` function's behavior.  The `take` function is a method of a kind of parametric module or "object" in OOP terms.  In Noelm terms, `take` is a method of an extensible record of type `Taker`.  We can create a new `Taker` object by passing the `newTaker` function some `TakerOptions`.

We want to use the `standardTaker` from the `PositionMarking` module.  This taker is configured to accept `PositionMarked` input and produce nice error messages with line and column numbers if something goes wrong.  For convenience, we will define `t` as an aliase to this `standardTaker`:

````
t = standardTaker
````

#### Exceptions

Our parser should report errors when there is unexpected input.  It should also report an error if it reaches the end of the file before it is done reading in the Name Location and Occupation that it was looking for.  One special case is that the line in which the occupation is listed does not necessarily need to end with a newline.  There could be an end of input there instead.  This can be easilly worked around in several ways.  We could provide a special case for dealing with the last entry. I think it is more elegant simply to append an extra newline to the end of the input.

#### Our main function
|]
 ,[markdown|

````
parseUserData: String -> FinalParserResult UserData
parseUserData unparsed =
 parse
  (  PM.charsToPositionMarkedChars
  <| String.toList unparsed ++ ['\n'])
  parseUserData'
````
|]
 ,[markdown|
First we prepare our input:

 - Convert it from a String to a [Char]
 - Append the newline
 - Mark each character with line-column markings

Then we pass it on to a Parser:

#### Our Parser
|]
 ,[markdown|

````
parseUserData': Parser (PositionMarked Char) UserData
parseUserData' =
 t.take nameField <| \ _ ->
 t.take tillEndOfLineUnpadded <| \ name ->
 fastforward 1 <|
 t.take locationField <| \ _ ->
 t.take tillEndOfLineUnpadded <| \ location ->
 fastforward 1 <|
 t.take occupationField <| \ _ ->
 t.take tillEndOfLineUnpadded <| \ occupation ->
 tillEndOfInput
  (Parsed
   {name=name
   ,location=location
   ,occupation=occupation})
  <| t.take whitespace
  <| \ _ ->
   t.lookAhead 1 <| \ notWhitespace input ->
   parseErrorAts
    {message =
         "Unexpected input "
      ++ (show notWhitespace)
      ++ " near end of file."
    ,expected = Just "end of input"}
    input
````

|]
 ,[markdown|
Here we `take` things in the order that they should appear in the file.  That weird `<| \ _ ->` notation is just us passing a lamda which defines a Continuation.  It is similar to the syntax we see in Philip Wadler's 1992 paper ["The Essence of Functional Programming."](http://homepages.inf.ed.ac.uk/wadler/topics/monads.html).

PS: That paper is a good read for those who might be looking at doing monad like stuff in Noelm as all of its examples are written without taking advantage of typeclasses or do-notation.  For the same reason, it is a good read for anyone just generally confused about monads.

````
t.take foo <| \ a ->
t.take bar <| \ b ->
(\ input -> Parsed (a,b))
````

 ===

````
t.take foo (\ a ->
t.take bar (\ b ->
(\ input -> Parsed (a,b))))
````

 ~=

````
do
 a <- take foo
 b <- take bar
 return (Parsed (a,b))
````

**What are all those fastforwards for?**  We put fastforwards after takes when we want to ignore the transition between two lexemes.  In this case `take tillEndOfLineUnpadded` leaves us at the transition '\n'.  We aren't interested in the newline, so we fast forward past it.

#### Our LexemeEaters

I've yet to define several LexemeEaters; `nameField`,`locationField`, and `occupationField` are defined bellow as:
|]
 ,[markdown|

````
field: String -> LexemeEater Char [Char]
field name = exactStringMatch (name++":")
nameField = field "Name"
locationField = field "Location"
occupationField = field "Occupation"
````
|]
 ,[markdown|

We still have one last LexemeEater to define and that is:
|]
 ,[markdown|

````
tillEndOfLineUnpadded
 = lexeme (\c->c/='\n') (String.trim . String.fromList)
````
|]
 ,[markdown|

This LexemeEater is built with the `lexeme` function. The `lexeme` function takes two functions as arguments `test: char -> Bool` and `conversion: [char] -> output`.  The LexemeEater produced by `lexeme` will eat so long as `test` is positive for the current next-character.  The intermediate value that it produces is the eaten input as passed through the `conversion` function.  Our conversion function turns the input into a string and removes whitespace from either side.

Finally, the `whitespace` LexemeEater used in this example is the same as the one defined near the beginning of this tutorial.  We could also use `whitespace` from the `Parsers.ContinuationParsers.Specifics.Lexemes` module.

You can play with this parser bellow ([Source](https://github.com/timthelion/noelm-continuation-parser/blob/master/src/Parsers/ContinuationParser/Examples/ParseUserData.noelm)):
|]]

(userDataField,userDataInput) =
 FieldExtras.fieldMultilineWithDefaultText
  "Enter some UserData to be parsed here."
  "Name: Suzana\nLocation: Rome\nOccupation: System Architect"

userDataOutput = (\input->asText <| ParseUserData.parseUserData input) <~ userDataInput